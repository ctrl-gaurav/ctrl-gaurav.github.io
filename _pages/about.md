---
permalink: /
title: "Welcome to Gaurav's Homepage!"
excerpt: "About me"
author_profile: true
redirect_from:
  - /about/
  - /about.html
---

<br>

**Note:** *This webpage was last updated on **10/20/2025.***

## About me

Hi folks, welcome to my personal homepage! I'm a first-year MS (thesis) student in Computer Science at [Virginia Tech](https://vt.edu/), and fortunately advised by [Dr. Xuan Wang](https://xuanwang91.github.io/). I am also affiliated with the [Sanghani Center for Artificial Intelligence and Data Analytics](https://sanghani.cs.vt.edu/person/gaurav-srivastava/). 

My research interests are in natural language processing, small and large language models, agentic systems and their applications in real-world domains, particularly in areas intersecting reasoning and efficiency. I have published papers in **EMNLP main conference** and other top-tier **(Q1) journals**. Most recently, I spent Summer 2025 at **Dell Technologies' Global Office of the CTO**, where I designed an agentic AI approach to autonomous resource allocation and was the recipient of **3 Inspire Recognition Awards** for positioning Dell PowerEdge as "AI-native" infrastructure.

Prior to joining Virginia Tech, I got my Bachelor's degree in Computer Science from Manipal University Jaipur in July 2023. During my Bachelor's program, I was fortunate to be supervised by [Dr. Nitesh Pradhan](https://scholar.google.co.in/citations?hl=en&user=bHEoi4YAAAAJ&view_op=list_works) and worked with [Dr. Vijaypal Singh Dhaka](https://scholar.google.com/citations?user=t9kU8QUAAAAJ&hl=en) and [Dr. Mahesh Jangid](https://scholar.google.co.in/citations?user=ChR5WYcAAAAJ&hl=en). I was also the President's Gold Medalist for Excellence in Research. After that I worked at Dell Technologies for 1 year as a Machine Learning Engineer. Before that, I spent 6 months at Swiggy's Applied Research (Computer Vision) team.

## Research‚ÄØ Interests

I work on **improving small language models in reasoning**‚Äîpushing lightweight LMs to think deeper, act smarter, and collaborate like expert teams. My research spans natural‚Äëlanguage processing, complex reasoning, and model efficiency, all aimed at creating _efficient, low‚Äëcost_ AI systems. My current focus areas include:

1. **Complex Reasoning in Small Language Models & Multi‚ÄëAgent Self‚ÄëEvolution:**
     _How far can carefully designed prompting, multi-agent debate, and iterative fine‚Äëtuning push models with only a few billion parameters?_ I study emergent reasoning, chain‚Äëof‚Äëthought, and which facets of reasoning are **kept or lost** after compression‚Äîrevealing **when and why** small models **succeed or fail** (see [**ThinkSLM**](https://arxiv.org/abs/2502.11569)). I also design systems where multiple LMs critique, refine, and distill each other's outputs. Iteratively fine‚Äëtuning the resulting "debate traces" lets a single model _self‚Äëevolve_ without human‚Äëlabeled data (see [**DEBATE, TRAIN, EVOLVE**](https://arxiv.org/abs/2505.15734)).

  2. **Benchmark-Free Evaluation & Overthinking in Language Models:**
     Evaluating language models fairly is becoming harder as static benchmarks risk contamination by training data. I developed [**BeyondBench**](https://ctrl-gaurav.github.io/BeyondBench/), an evaluation framework using algorithmic problem generation that creates mathematically grounded problems on the fly‚Äîeach from a combinatorial space larger than 10^15 unique instances. I also study the accuracy-efficiency tradeoff: _Do language models waste cognitive cycles on problems that humans solve almost reflexively?_ My work on [**Overthinking in LLMs**](https://github.com/ctrl-gaurav/LLMThinkBench) reveals that reasoning models generate ~18√ó more tokens while sometimes achieving lower accuracy, with extended reasoning budgets yielding diminishing returns.

  3. **Agentic AI with Small Language Models:**
     I envision a future where _efficient, specialized AI agents_ powered by small language models can autonomously collaborate to solve complex real-world problems. My work bridges the gap between research and production by building systems that not only reason better but also **act smarter**‚Äîorchestrating multiple agents, managing resources intelligently, and delivering practical impact at scale with minimal computational overhead.

## News

- **[Oct. 8, 2025]** New **[preprint](https://arxiv.org/abs/2507.04023v2)** on benchmarking the accuracy-efficiency tradeoff in language models for basic math reasoning!
- **[Sep. 30,‚ÄØ2025]** Released **[BeyondBench](https://ctrl-gaurav.github.io/BeyondBench/)**&mdash;the Benchmark-Free Reasoning‚ÄØEvaluation of LLMs Leaderboard!
- **[Sep. 29,‚ÄØ2025]** New **[preprint](https://arxiv.org/abs/2509.24210)** on benchmark-free evaluation of reasoning in language models!
- **[Aug. 20,‚ÄØ2025]** üéâ Two of my papers (**[ThinkSLM](https://arxiv.org/abs/2502.11569)** and **[DEBATE, TRAIN, EVOLVE](https://arxiv.org/abs/2505.15734)**) got accepted to **EMNLP 2025 Main** Conference!
- **[Aug. 13,‚ÄØ2024]** üéâ Received **3 Inspire Recognition Awards** from **[Dell‚ÄØTechnologies](https://www.dell.com/en-us)** Global CTO's office for my internship work in Agentic AI for Autonomous Resource Allocation!
- **[Jul. 5,‚ÄØ2025]** New **[preprint](https://arxiv.org/abs/2507.04023)** on basic math reasoning and overthinking in LLMs!
- **[May. 27,‚ÄØ2025]** Started my summer internship @ Dell Office of the CTO&mdash;Digital Skills Research!
- **[May. 21,‚ÄØ2025]** New **[preprint](https://arxiv.org/abs/2505.15734)** on self-evolution of language model reasoning!
- **[May. 10,‚ÄØ2025]** Released the **[LLMThinkBench](https://ctrl-gaurav.github.io/llmthinkbench.github.io/)** Leaderboard! Currently there are **17** open-sourced and **4** proprietary models!
- **[May. 4,‚ÄØ2025]** Released the **[DataSense](https://github.com/ctrl-gaurav/DataSense)** framework for data visualization and story generation using language models&mdash;install it with `pip install datasense`!
- **[Apr. 22,‚ÄØ2025]** Released **[ThinkSLM](https://ctrl-gaurav.github.io/thinkslm.github.io/)**&mdash;the SLM‚ÄØReasoning‚ÄØLeaderboard!
- **[Apr. 5,‚ÄØ2025]** Released the **[LLMThinkBench](https://github.com/ctrl-gaurav/LLMThinkBench)** framework for evaluating basic‚Äëmath reasoning and over‚Äëthinking in language models&mdash;install it with `pip install llmthinkbench`!
- **[Feb. 17,‚ÄØ2025]** New **[preprint](https://arxiv.org/abs/2502.11569)** on the reasoning abilities of small language models.
- **[Oct. 9,‚ÄØ2024]** Accepted a Summer 2025 internship offer at **[Dell‚ÄØTechnologies](https://www.dell.com/en-us)** as an AI‚ÄØResearch‚ÄØIntern in the Global Office of the CTO (Round‚ÄØRock,‚ÄØTX)!
- **[Sep. 4,‚ÄØ2024]** Joined **[Wang‚Äôs‚ÄØGroup](https://xuanwang91.github.io/lab)** to work on reasoning, small language models, and large language models!
- **[Aug. 6,‚ÄØ2024]** Began my M.S. in Computer Science at Virginia Tech!


## Honors and Awards

- üèÜ **3 Inspire Recognition Awards** for positioning Dell PowerEdge as "AI-native" infrastructure, Dell Technologies (2025)
- ü•á **President's Gold Medal** for Excellence in Research, Manipal University Jaipur (2023)
- ü•à **Runner-up**, Dell IT Development Program (ITDP) FY'23 Hackathon, Dell Technologies (2023)
- ü™ô **Ranked 13/473** globally in Bitgrit Generative AI Competition, Bitgrit (2023)
- ü™ô **117/26,008**, Amazon ML Challenge 2023, Amazon (2023)
- ü•á **Three-time recipient** of the Student Excellence Award for publishing research, MUJ (2022 - 2023)
- ü•á **Best Research Project**, Computer Science Department, Manipal University Jaipur (2022)
- ü•â **All India Grand Finalist**, Precision Health Challenge 2021-22 Hackathon, Wipro GE Healthcare (2022)
- ü•â **All India Grand Finalist**, India Automobile Hackathon, NEC and Mitsubishi (2022)
- ü•â **All India Grand Finalist**, HACKBATTLE: Impact Through Data Hackathon, T-Systems (2022)
- ü•â **3rd Position, "Hack2Hire"** Hackathon, Dell Technologies (2021)
- ü•á **Best Senior Hack**, NPSiHacks, Devfolio (2021)
- ü™ô **Kaggle 3X Expert** (Top 20% in Competitions, Top 1% in Titanic, Digit Recognizer) (2020 - 2023)