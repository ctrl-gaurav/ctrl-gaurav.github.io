---
permalink: /
title: "Welcome to Gaurav's Homepage!"
excerpt: "About me"
author_profile: true
redirect_from:
 - /about/
 - /about.html
---

<br>

**Note:** *This webpage was last updated on **05/02/2025.***

## About me

Hi folks, welcome to my personal homepage! I'm a first-year MS (thesis) student in Computer Science at [Virginia Tech](https://vt.edu/), and fortunately advised by [Dr. Xuan Wang](https://xuanwang91.github.io/). I am also affiliated with the [Sanghani Center for Artificial Intelligence and Data Analytics](https://sanghani.cs.vt.edu/person/gaurav-srivastava/).

Prior to joining Virginia Tech, I got my Bachelor's degree in Computer Science from Manipal University Jaipur in July 2023. During my Bachelor's program, I was fortunate to be supervised by [Dr. Nitesh Pradhan](https://scholar.google.co.in/citations?hl=en&user=bHEoi4YAAAAJ&view_op=list_works) and worked with [Dr. Vijaypal Singh Dhaka](https://scholar.google.com/citations?user=t9kU8QUAAAAJ&hl=en) and [Dr. Mahesh Jangid](https://scholar.google.co.in/citations?user=ChR5WYcAAAAJ&hl=en). I was also the President's Gold Medalist for Excellence in Research. After that I worked at Dell Technologies for 1 year as a Machine Learning Engineer. Before that, I spent 6 months at Swiggy's Applied Research (Computer Vision) team. 

## Researchâ€¯ Interests

I work on **improving small language models in reasoning**â€”pushing lightweight LMs to think deeper, act smarter, and collaborate like expert teams. My research spans naturalâ€‘language processing, complex reasoning, and model efficiency, all aimed at creating *efficient, lowâ€‘cost* AI systems. My current focus areas include:

1. **Complex Reasoning in Small Language Models:**  
  *How far can carefully designed prompting, multi-agent debate, and iterative fineâ€‘tuning push models with only a few billion parameters?* I study emergent reasoning, chainâ€‘ofâ€‘thought, and which facets of reasoning are **kept or lost** after compressionâ€”revealing **whenâ€¯ and â€¯why** small models **succeed or fail**.

2.  **Multiâ€‘Agent Debate & Selfâ€‘Evolution:**  
 I design systems where multiple LMs critique, refine, and distill each otherâ€™s outputs. Iteratively fineâ€‘tuning the resulting â€œdebate tracesâ€ lets a single model *selfâ€‘evolve* without humanâ€‘labeled data.

3. **Overthinking in Basic Reasoning:**  
   *Do language models waste cognitive cycles on problems that humans solve almost reflexively?* I also study when language models overthink problems that humans solve instinctively. I developed [**LLMThinkBench**](https://github.com/ctrl-gaurav/LLMThinkBench), a framework that measures whenâ€”and whyâ€”LLMs *overthink* straightforward math and logical reasoning tasks.

---

<!-- - Natural Language Processing
- Complex Reasoning
- Small Language Models
- Efficient Large Language Models
- Multi-Agent Systems -->

## News

- **[Apr. 22,â€¯2025]** Released the [SLMâ€¯Reasoningâ€¯Leaderboard](https://ctrl-gaurav.github.io/slms-reasoning-leaderboard.github.io/)!
- **[Apr. 5,â€¯2025]** Released the [LLMThinkBench](https://github.com/ctrl-gaurav/LLMThinkBench) framework for evaluating basicâ€‘math reasoning and overâ€‘thinking in language models&mdash;install it with `pip install llmthinkbench`!
- **[Feb. 17,â€¯2025]** New [preprint](https://arxiv.org/abs/2502.11569) on the reasoning abilities of small language models.
- **[Oct. 9,â€¯2024]** Accepted a Summer&nbsp;2025 internship offer at [Dellâ€¯Technologies](https://www.dell.com/en-us) as an AIâ€¯Researchâ€¯Intern in the Global Office of the CTO (Roundâ€¯Rock,â€¯TX)!
- **[Sep. 4,â€¯2024]** Joined [Wangâ€™sâ€¯Group](https://xuanwang91.github.io/lab) to work on reasoning, small language models, and large language models!
- **[Aug. 6,â€¯2024]** Began my M.S. in Computer Science at Virginia Tech!


<!-- ## News

- **(22/4/25)** We release [SLM Reasoning Leaderboard](https://ctrl-gaurav.github.io/slms-reasoning-leaderboard.github.io/)!
- **(5/4/25)** Released [LLMThinkBench](https://github.com/ctrl-gaurav/LLMThinkBench) framework for evaluating basic math reasoning and overthinking in language models. Check it out here [**pip install llmthinkbench**](https://pypi.org/project/llmthinkbench/)!
- **(17/2/25)** New [preprint](https://arxiv.org/abs/2502.11569) on reasoning ability of small language models!
- **(10/9/24)** Got summer'25 internship offer to join [Dell Technologies](https://www.dell.com/en-us) as an **AI Research Intern** at the Global Office of the **CTO** (Round Rock, TX)!
- **(9/4/24)** Joined [Wang's Group](https://xuanwang91.github.io/lab). Looking forward to work on Reasoning, small language models and large language models!
- **(8/6/24)** Joined Virginia Tech to start Master's in Computer Science! -->

## Honors and Awards

- ğŸ¥‡ **President's Gold Medal** for Excellence in Research, Manipal University Jaipur (2023)
- ğŸ¥ˆ **Runner-up**, Dell IT Development Program (ITDP) FY'23 Hackathon, Dell Technologies (2023)
- ğŸª™ **Ranked 13/473** globally in Bitgrit Generative AI Competition, Bitgrit (2023)
- ğŸª™ **117/26,008**, Amazon ML Challenge 2023, Amazon (2023)
- ğŸ¥‡ **Three-time recipient** of the Student Excellence Award for publishing research, MUJ (2022 - 2023)
- ğŸ¥‡ **Best Research Project**, Computer Science Department, Manipal University Jaipur (2022)
- ğŸ¥‰ **All India Grand Finalist**, Precision Health Challenge 2021-22 Hackathon, Wipro GE Healthcare (2022)
- ğŸ¥‰ **All India Grand Finalist**, India Automobile Hackathon, NEC and Mitsubishi (2022)
- ğŸ¥‰ **All India Grand Finalist**, HACKBATTLE: Impact Through Data Hackathon, T-Systems (2022)
- ğŸ¥‰ **3rd Position, "Hack2Hire"** Hackathon, Dell Technologies (2021)
- ğŸ¥‡ **Best Senior Hack**, NPSiHacks, Devfolio (2021)
- ğŸª™ **Kaggle 3X Expert** (Top 20% in Competitions, Top 1% in Titanic, Digit Recognizer) (2020 - 2023)

